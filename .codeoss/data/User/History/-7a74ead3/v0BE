import vertexai
from vertexai.preview import rag
from vertexai.generative_models import GenerativeModel, Tool
import asyncio

# Step 1: Set up your Google Cloud Project ID
PROJECT_ID = "my-rag-project-455210"  # Update with your actual project ID
LOCATION = "us-central1"

# Step 2: Initialize Vertex AI
vertexai.init(project=PROJECT_ID, location=LOCATION)

# Step 3: Create Corpus and Set Embedding Model
corpus_display_name = "my_rag_corpus"
corpora = rag.list_corpora()
existing_corpus = next((c for c in corpora if c.display_name == corpus_display_name), None)

if existing_corpus:
    print(f"‚úÖ Using existing corpus: {corpus_display_name}")
    corpus = existing_corpus
else:
    print(f"üìå Creating new corpus: {corpus_display_name}")
    # Create Corpus without RagVectorDbConfig and EmbeddingModelConfig
    corpus = rag.create_corpus(display_name=corpus_display_name)

# Step 4: Import Files from Google Cloud Storage
async def import_files():
    paths = ["gs://rag-bucket-sandyaakevin-12345/ch2.docx"]  # Update with your GCS bucket path
    print("üìÇ Importing files into RAG Corpus...")
    
    # Chunking configuration (optional)
    transformation_config = rag.TransformationConfig(
        chunking_config=rag.ChunkingConfig(
            chunk_size=512,  # Adjust chunk size if needed
            chunk_overlap=100,  # Adjust chunk overlap if needed
        ),
    )

    # Asynchronously import files
    await rag.import_files_async(
        corpus.name,
        paths,
        transformation_config=transformation_config,  # Optional
        max_embedding_requests_per_min=1000  # Optional limit
    )
    print("‚úÖ Files imported successfully.")
    print("üìÇ Files in RAG Corpus:", rag.list_files(corpus.name))

# Run the file import function
asyncio.run(import_files())

# Step 5: Retrieve Context from RAG
print("üîç Running a RAG retrieval query...")

# Configure retrieval query settings (e.g., top_k results and filter)
rag_retrieval_config = rag.RagRetrievalConfig(
    top_k=3,  # Optional: limit number of returned results
    filter=rag.Filter(vector_distance_threshold=0.5)  # Optional: filter based on vector distance
)

response = rag.retrieval_query(
    rag_resources=[rag.RagResource(rag_corpus=corpus.name)],
    text="Summarize the document",  # Example query
    rag_retrieval_config=rag_retrieval_config  # Pass retrieval config
)
print("RAG Response:", response)

# Step 6: Use RAG-Enhanced Generation with Gemini Model
rag_retrieval_tool = Tool.from_retrieval(retrieval=rag.Retrieval(
    source=rag.VertexRagStore(
        rag_resources=[rag.RagResource(rag_corpus=corpus.name)],
        rag_retrieval_config=rag_retrieval_config  # Include retrieval config here
    ),
))

# Instantiate GenerativeModel with RAG tool
rag_model = GenerativeModel(model_name="gemini-2.0-flash-001", tools=[rag_retrieval_tool])

# Generate content based on the retrieval
gen_response = rag_model.generate_content("Summarize the document")
print("Generated Response:", gen_response.text)
